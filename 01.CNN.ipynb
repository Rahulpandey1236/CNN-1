{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef50cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## to read about cnn on colab \n",
    "## run all these code on Colab \n",
    "https://colab.research.google.com/drive/1nD2-YEsK1ZReOfVK_jc3I4X07t3O_aK_#scrollTo=yl1XKIs8xclH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45c35ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "# Imports a Flatten layer to convert the image matrix into a vector\n",
    "# Defines the neural network architecture\n",
    "model.add( Flatten(input_shape = (28,28) ))\n",
    "model.add(Dense(512, activation = 'relu'))\n",
    "model.add(Dense(512, activation = 'relu'))\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7097283",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from google.colab.patches import cv2_imshow\n",
    "import os, json, cv2, random\n",
    "\n",
    "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O input.jpg\n",
    "im = cv2.imread(\"./input.jpg\")\n",
    "cv2_imshow(im)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafd13b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb47996",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O input.jpg\n",
    "image = cv2.imread(\"./input.jpg\")\n",
    "cv2_imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b46e888",
   "metadata": {},
   "outputs": [],
   "source": [
    "## read the image\n",
    "image = mpimg.imread('input.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c677e805",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d77bbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image[:,:,0]) ## R channel\n",
    "image[:,:,1] ## G chaneel\n",
    "image[:,:,2] ## b channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae24d865",
   "metadata": {},
   "outputs": [],
   "source": [
    "## isolate RGB channels\n",
    "r = image[:,:,0]\n",
    "g = image[:,:,1]\n",
    "b = image[:,:,2]\n",
    "\n",
    "## visualize the individuals color channels\n",
    "f,(ax1,ax2,ax3) = plt.subplots(1,3,figsize = (20,10))\n",
    "ax1.set_title('R channel')\n",
    "ax1.imshow(r)\n",
    "ax2.set_title('G channel')\n",
    "ax2.imshow(g)\n",
    "ax3.set_title('B channel')\n",
    "ax3.imshow(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8397b7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "## read the image\n",
    "image = mpimg.imread('input.jpg')\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c02b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert to grayscale for filtering\n",
    "gray = cv2.cvtColor(image , cv2.COLOR_RGB2GRAY)\n",
    "plt.imshow(gray,cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae73ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc05f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## horizontal edge detection\n",
    "sobel_y = np.array([[-1,-2,-1],\n",
    "                    [0,0,0],\n",
    "                    [1,2,1]]\n",
    "                   )\n",
    "\n",
    "## vertical edge detection\n",
    "sobel_x = np.array([[-1,0,1],\n",
    "                    [-2,0,1],\n",
    "                    [-1,0,1]])\n",
    "\n",
    "## filter the image using filter2d (grayscale , image , bit-depth , kernel )\n",
    "filtered_image1 = cv2.filter2D(gray , -1,sobel_x)\n",
    "filtered_image2 = cv2.filter2D(gray , -1,sobel_y)\n",
    "\n",
    "f,ax = plt.subplots(1,2,figsize = (15,4))\n",
    "ax[0].set_title('horizontal edge detection')\n",
    "ax[0].imshow(filtered_image1 , cmap = 'gray')\n",
    "ax[1].set_title('vertical edge detection')\n",
    "ax[1].imshow(filtered_image2 , cmap ='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b204bf7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
